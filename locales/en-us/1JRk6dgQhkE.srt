1
00:00:00,430 --> 00:00:01,580
How about variability?

2
00:00:01,580 --> 00:00:04,860
First, we said, here's how to compute
the variability analytically.

3
00:00:04,860 --> 00:00:08,170
But then, we said, sometimes it's maybe
better to estimate it empirically.

4
00:00:08,170 --> 00:00:09,860
Which should I be doing?

5
00:00:09,860 --> 00:00:13,200
>> Well, it's usually good to start
out with some kind of analytical

6
00:00:13,200 --> 00:00:15,480
characterization of your variability.

7
00:00:15,480 --> 00:00:17,150
Sometimes, that's even sufficient.

8
00:00:17,150 --> 00:00:20,670
But, if nothing else, it means that you
have to look at the distribution, and

9
00:00:20,670 --> 00:00:22,070
start to get a feel for your data.

10
00:00:22,070 --> 00:00:25,020
Which is really important
as part of this process.

11
00:00:25,020 --> 00:00:28,000
In some cases, like where you're
using counts, or probabilities,

12
00:00:28,000 --> 00:00:32,130
or averages, your data is fairly nice,
it may be sufficient.

13
00:00:32,130 --> 00:00:35,120
Or, it may give you a good sense
of how to size your experiment.

14
00:00:35,120 --> 00:00:37,460
So, at least,
you can tell if you're in the ballpark.

15
00:00:37,460 --> 00:00:38,120
>> I agree.
I mean,

16
00:00:38,120 --> 00:00:41,080
you should always start with
at least a basic analytical

17
00:00:41,080 --> 00:00:42,800
estimate of your variability.

18
00:00:42,800 --> 00:00:46,440
Now, where we sort of encounter
the problem is that with a metric like

19
00:00:46,440 --> 00:00:48,490
revenue per query,

20
00:00:48,490 --> 00:00:52,300
it's actually very difficult to compute
the variability of that analytically.

21
00:00:52,300 --> 00:00:53,990
It turns out that for some metrics,

22
00:00:53,990 --> 00:00:58,270
it was actually easier to compute it
empirically as opposed to analytically.

23
00:00:58,270 --> 00:01:01,190
And, once we're just computing that
empirically, then we were like, well,

24
00:01:01,190 --> 00:01:04,230
we may as well try it for
all the other metrics.

25
00:01:04,230 --> 00:01:07,640
Which is when we discovered some of the
discrepancies between the analytical and

26
00:01:07,640 --> 00:01:10,800
the empirical calculation, even for
something like a probability.

27
00:01:10,800 --> 00:01:14,230
We'll be discussing the reason for
that more in lesson 4

28
00:01:14,230 --> 00:01:16,560
>> Okay, and just overall,

29
00:01:16,560 --> 00:01:19,350
what are some of the main lessons
you've learned about metrics?

30
00:01:19,350 --> 00:01:21,990
>> You know, the one that I
keep going back to over and

31
00:01:21,990 --> 00:01:26,780
over again is the necessity of
invariance, or sanity checking, right?

32
00:01:26,780 --> 00:01:29,240
I went back to the very first
experiment that Google ran,

33
00:01:29,240 --> 00:01:33,580
which is back in the year 2000, where we
tested out should we showing 10 results,

34
00:01:33,580 --> 00:01:35,612
20 results, or 30 results.

35
00:01:35,612 --> 00:01:37,890
It seemed a very
straightforward experiment,

36
00:01:37,890 --> 00:01:39,730
but the results were
actually really weird.

37
00:01:39,730 --> 00:01:43,822
And, what we actually found was that it
was because the latency was changing as

38
00:01:43,822 --> 00:01:45,249
we ran those experiments.

39
00:01:45,249 --> 00:01:48,058
That was actually causing
the change in the user response,

40
00:01:48,058 --> 00:01:49,865
as opposed to the number of resolves.

41
00:01:49,865 --> 00:01:53,196
And so, in that situation,
using the latency as an invariant,

42
00:01:53,196 --> 00:01:56,840
as opposed to evaluation
metric,was the right answer.

43
00:01:56,840 --> 00:02:01,000
>> Now, there's another story where,
for a variety of reasons,

44
00:02:01,000 --> 00:02:05,430
we accidentally put an IFrame,
an invisible IFrame, over the ads.

45
00:02:05,430 --> 00:02:09,845
And so, at least in some browsers,
you actually couldn't click on the ad.

46
00:02:09,845 --> 00:02:13,795
Being able to know and say, oh,
well when click-through rate changes by,

47
00:02:13,795 --> 00:02:17,095
that large an amount,
that's just simply not possible.

48
00:02:17,095 --> 00:02:20,645
That is also, like, a really big
thing to understand, and know,

49
00:02:20,645 --> 00:02:23,092
and have intuition about your system.

50
00:02:23,092 --> 00:02:26,252
>> You also have to just sort of see
how these things behave in practice.

51
00:02:26,252 --> 00:02:29,697
When we first started looking at
what made a bad query, a query where

52
00:02:29,697 --> 00:02:33,292
a user didn't find the results they
were hoping for in their search.

53
00:02:33,292 --> 00:02:35,332
The thing that everybody said is, well,

54
00:02:35,332 --> 00:02:39,156
a bad query is the query where people
click on a bunch of results, like two or

55
00:02:39,156 --> 00:02:41,306
more results, or
they hit the next page button.

56
00:02:41,306 --> 00:02:44,716
Because, they obviously haven't found
what they wanted on the first page.

57
00:02:44,716 --> 00:02:47,896
Now, it turned out very quickly that,
that wasn't a great way to pick out bad

58
00:02:47,896 --> 00:02:52,900
queries, because you've heard the song
from Avenue Q, The Internet is for Porn?

59
00:02:52,900 --> 00:02:54,598
Well, we get a lot of porn queries, and

60
00:02:54,598 --> 00:02:56,774
for various reasons,
we won't talk about here.

61
00:02:56,774 --> 00:03:00,118
It appears that they all
basically look like that.

62
00:03:00,118 --> 00:03:03,342
And so, we were really just picking
out a lot of sort of browsing porn

63
00:03:03,342 --> 00:03:04,540
queries in the process.

64
00:03:05,725 --> 00:03:08,915
The second thing that came up here,
which is more sort of time critical,

65
00:03:08,915 --> 00:03:11,835
is when we first started
using these metrics,

66
00:03:11,835 --> 00:03:15,405
people were really using search
engines for navigational results.

67
00:03:15,405 --> 00:03:17,305
They were looking for
a particular store,

68
00:03:17,305 --> 00:03:19,385
looking for a particular home page.

69
00:03:19,385 --> 00:03:22,145
And so, you really got this behavior
where people did a query, and

70
00:03:22,145 --> 00:03:24,395
then they clicked on the first result,
and they were happy.

71
00:03:24,395 --> 00:03:26,130
They found what they wanted.

72
00:03:26,130 --> 00:03:28,940
But today, the amount of content
on the internet is more diverse,

73
00:03:28,940 --> 00:03:32,140
plus people have gotten used to
search engines being smart, so

74
00:03:32,140 --> 00:03:34,610
they really do more complicated tasks.

75
00:03:34,610 --> 00:03:36,400
And, even if you're looking for
a person,

76
00:03:36,400 --> 00:03:38,900
you might end up clicking
on their Twitter feed,

77
00:03:38,900 --> 00:03:42,560
you click on their Facebook page,
you click on their university home page.

78
00:03:42,560 --> 00:03:44,720
So, the behavior has really shifted.

79
00:03:44,720 --> 00:03:48,090
And, this is a good example of
a metric that seemed like a good idea,

80
00:03:48,090 --> 00:03:51,680
worked at a particular point in time,
or didn't work, and then, sort of,

81
00:03:51,680 --> 00:03:54,490
stopped working as the use
case evolved for the website.
