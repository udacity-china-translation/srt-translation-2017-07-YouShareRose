1
00:00:00,400 --> 00:00:02,485
Now, let's move on to
the second use I mentioned for

2
00:00:02,485 --> 00:00:06,180
A/A tests, where we can estimate
the variance empirically

3
00:00:06,180 --> 00:00:08,820
if we weren't able to
calculate it analytically.

4
00:00:08,820 --> 00:00:11,330
I'll actually compute
the standard deviation instead,

5
00:00:11,330 --> 00:00:14,310
since that's the direct
analog of standard error.

6
00:00:14,310 --> 00:00:17,360
And, I do that by taking
the standard deviation

7
00:00:17,360 --> 00:00:20,450
of each of the twenty differences
from the smallest experiments.

8
00:00:20,450 --> 00:00:22,530
And, for that size of experiment,

9
00:00:22,530 --> 00:00:26,500
I get that the standard deviation
of the difference is 0.059.

10
00:00:26,500 --> 00:00:30,530
I can also do the same thing for
each of the other experiment sizes.

11
00:00:30,530 --> 00:00:31,870
I won't show that here, but, again,

12
00:00:31,870 --> 00:00:35,210
you can find the results in the sheet
linked in the instructor's notes.

13
00:00:35,210 --> 00:00:38,770
Now, since we expect that our metric
follows roughly a normal distribution,

14
00:00:38,770 --> 00:00:42,660
we can compute the margin of error
as the standard deviation we just

15
00:00:42,660 --> 00:00:45,890
calculated times the Z-square
of our confidence level.

16
00:00:45,890 --> 00:00:49,520
This is the same equation you saw for
the margin of error in lesson one, but

17
00:00:49,520 --> 00:00:53,620
with the empirical standard deviation
instead of the analytic standard error.

18
00:00:53,620 --> 00:00:57,356
If you didn't know beforehand whether to
expect your metric to follow a normal

19
00:00:57,356 --> 00:01:01,035
distribution, then you might look at
histograms like the ones we just looked

20
00:01:01,035 --> 00:01:04,677
at to see whether the metric looked
like it followed a normal distribution.

21
00:01:04,677 --> 00:01:09,214
If we do that for the small experiment
we just looked at with a 95%

22
00:01:09,214 --> 00:01:14,011
confidence level, then the margin
of error comes out to 0.116.

23
00:01:14,011 --> 00:01:17,302
Remember, if we had done this
analytically, the standard error depends

24
00:01:17,302 --> 00:01:21,220
on the pooled probability, which will
be different for each experiment.

25
00:01:21,220 --> 00:01:24,260
That means we actually would have gotten
a slightly different margin of error for

26
00:01:24,260 --> 00:01:25,500
each experiment.

27
00:01:25,500 --> 00:01:27,028
Whereas, empirically,

28
00:01:27,028 --> 00:01:30,713
we calculated one margin of error
across all the experiments.

29
00:01:30,713 --> 00:01:34,650
If I do calculate the pooled probability
and the pooled standard error for

30
00:01:34,650 --> 00:01:35,667
each experiment,

31
00:01:35,667 --> 00:01:40,130
I see that the pooled standard error
varies, but it is always close to 0.059.

32
00:01:40,130 --> 00:01:43,350
So, we're getting roughly
the same results either way.

33
00:01:43,350 --> 00:01:46,680
But if your metric doesn't seem
to follow a normal distribution,

34
00:01:46,680 --> 00:01:48,190
then what can you do?

35
00:01:48,190 --> 00:01:51,588
Well, you can also directly estimate a
confidence interval from the results of

36
00:01:51,588 --> 00:01:53,240
your A/A tests.

37
00:01:53,240 --> 00:01:55,650
This is the third use
case I mentioned earlier.

38
00:01:55,650 --> 00:01:58,280
The way to do this is take all your
differences and put them in order,

39
00:01:58,280 --> 00:02:02,690
in our case ranging from
negative 0.15 to positive 0.15.

40
00:02:02,690 --> 00:02:05,920
Then if you want a 95%
confidence interval,

41
00:02:05,920 --> 00:02:09,630
select a box that includes
only 95% of the values.

42
00:02:09,630 --> 00:02:12,490
That is discard 2.5% of
your values on each side.

43
00:02:13,580 --> 00:02:16,794
Then, the range of your remaining
data points will give you a 95%

44
00:02:16,794 --> 00:02:17,930
confidence level.

45
00:02:17,930 --> 00:02:21,839
Since we have 20 data points in our
smallest experiment group, dropping

46
00:02:21,839 --> 00:02:25,882
the highest and the lowest difference
give us a 90% confidence interval.

47
00:02:25,882 --> 00:02:29,748
For our data, that gives us
a lower bound of negative 0.1, and

48
00:02:29,748 --> 00:02:31,451
an upper bound of 0.06.

49
00:02:31,451 --> 00:02:36,050
Recall that the empirical standard
deviation I calculated a minute ago was

50
00:02:36,050 --> 00:02:36,933
0.059.

51
00:02:36,933 --> 00:02:41,142
Now, if I multiply that by
1.65 which is the z-score for

52
00:02:41,142 --> 00:02:45,800
a 90% confidence level,
then that comes to about 0.097.

53
00:02:45,800 --> 00:02:50,659
So, if the true difference were 0 that
would give us a confidence interval of

54
00:02:50,659 --> 00:02:53,683
negative 0.097 to positive 0.097.

55
00:02:53,683 --> 00:02:59,600
So, these two methods give a sort of
close answer, but it's not that close.

56
00:02:59,600 --> 00:03:03,250
The main reason for this is that
we only have 20 data points.

57
00:03:03,250 --> 00:03:06,570
You'd probably want to run more
A/A tests to actually trust

58
00:03:06,570 --> 00:03:11,060
this confidence interval, unless each
test was run for a pretty long time.

59
00:03:11,060 --> 00:03:14,740
You also can't differentiate
between a 90% confidence level and

60
00:03:14,740 --> 00:03:19,050
a 95% with only 20 tests, since the best
you can do is drop the lowest point and

61
00:03:19,050 --> 00:03:23,320
the highest point, which already takes
you down to a 90% confidence level.
