1
00:00:00,360 --> 00:00:02,969
This second result is
often called neutral.

2
00:00:02,969 --> 00:00:05,900
There's no statistically
significant change from 0

3
00:00:05,900 --> 00:00:08,590
since the confidence
interval includes 0 and

4
00:00:08,590 --> 00:00:12,560
you're also confident that there's
not a practically significant change.

5
00:00:12,560 --> 00:00:15,620
Given this it's not worth
the effort to launch the change.

6
00:00:15,620 --> 00:00:19,350
In the third case, your result
is statistically significant.

7
00:00:19,350 --> 00:00:22,370
Your confident, that is,
that there was a positive change, but

8
00:00:22,370 --> 00:00:23,890
it's not practically significant.

9
00:00:23,890 --> 00:00:27,630
In fact, you're confident that there was
not a practically significant change.

10
00:00:27,630 --> 00:00:29,960
In other words,
you're confident there was a change, but

11
00:00:29,960 --> 00:00:32,420
you don't care about
the magnitude of the change.

12
00:00:32,420 --> 00:00:35,170
Don't let your team celebrate
when they get a result like this.

13
00:00:35,170 --> 00:00:38,510
Again, it's not worth the effort
to launch this change.

14
00:00:38,510 --> 00:00:42,290
If it had been, you would've set your
practical significance boundary lower.

15
00:00:42,290 --> 00:00:45,320
This fourth case is one of the cases
that can be the most difficult to

16
00:00:45,320 --> 00:00:47,220
handle as an analyst.

17
00:00:47,220 --> 00:00:50,820
Some people call this a neutral
change just like change two, but

18
00:00:50,820 --> 00:00:54,130
here, the confidence interval bounds
are outside of what's practically

19
00:00:54,130 --> 00:00:55,440
significant.

20
00:00:55,440 --> 00:00:59,380
If you ran an experiment and found that
it could be causing your number of users

21
00:00:59,380 --> 00:01:03,780
to increase by 10% or it could be
causing them to decrease by 10%,

22
00:01:03,780 --> 00:01:06,320
would you say that
that change is neutral?

23
00:01:06,320 --> 00:01:09,140
Instead, it would be better to say
that you do not have enough power to

24
00:01:09,140 --> 00:01:10,890
draw a strong conclusion.

25
00:01:10,890 --> 00:01:13,920
Running an additional test with greater
power would be recommended in this

26
00:01:13,920 --> 00:01:15,810
situation, if possible.

27
00:01:15,810 --> 00:01:17,460
Here's another tricky case.

28
00:01:17,460 --> 00:01:20,670
The point estimate is beyond
what's practically significant.

29
00:01:20,670 --> 00:01:24,180
Meaning your best guess, is that this
change is an effect you care about.

30
00:01:24,180 --> 00:01:26,590
But the confidence interval overlaps 0,
so

31
00:01:26,590 --> 00:01:28,770
there might not even be a change at all.

32
00:01:28,770 --> 00:01:31,230
Do you launch assuming
that it is positive,

33
00:01:31,230 --> 00:01:33,860
even though it could
potentially have no effect.

34
00:01:33,860 --> 00:01:36,420
Repeating this test with greater
power would give additional

35
00:01:36,420 --> 00:01:38,070
confidence to the results.

36
00:01:38,070 --> 00:01:41,000
And finally,
this is another common tricky example.

37
00:01:41,000 --> 00:01:43,880
Again, your best guess is that
there is a practically significant

38
00:01:43,880 --> 00:01:45,180
positive change.

39
00:01:45,180 --> 00:01:49,230
However, it's also possible your
change is not practically significant.

40
00:01:49,230 --> 00:01:50,460
How do you make the call?

41
00:01:50,460 --> 00:01:51,730
For all of these last three cases,

42
00:01:51,730 --> 00:01:55,580
you should run an additional test with
greater power if you have the time.

43
00:01:55,580 --> 00:01:58,540
But sometimes you have to make a
decision even though there's uncertainty

44
00:01:58,540 --> 00:02:02,870
about how real your result is or
even about the direction of the result.

45
00:02:02,870 --> 00:02:05,610
Let's get some perspective from
Diane about these tricky cases.
